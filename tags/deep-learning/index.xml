<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | NTU Graph Deep Learning Lab</title>
    <link>https://graphdeeplearning.github.io/tags/deep-learning/</link>
      <atom:link href="https://graphdeeplearning.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Xavier Bresson Â© 2020</copyright><lastBuildDate>Tue, 14 Jan 2020 16:19:27 +0800</lastBuildDate>
    <image>
      <url>https://graphdeeplearning.github.io/img/icon-192.png</url>
      <title>Deep Learning</title>
      <link>https://graphdeeplearning.github.io/tags/deep-learning/</link>
    </image>
    
    <item>
      <title>Free-hand Sketches</title>
      <link>https://graphdeeplearning.github.io/project/sketches/</link>
      <pubDate>Tue, 14 Jan 2020 16:19:27 +0800</pubDate>
      <guid>https://graphdeeplearning.github.io/project/sketches/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi-Graph Transformer for Free-Hand Sketch Recognition</title>
      <link>https://graphdeeplearning.github.io/publication/xu-2019-multi/</link>
      <pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/xu-2019-multi/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Two-Step Graph Convolutional Decoder for Molecule Generation</title>
      <link>https://graphdeeplearning.github.io/publication/bresson-2019-two/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/bresson-2019-two/</guid>
      <description></description>
    </item>
    
    <item>
      <title>On Learning Paradigms for the Travelling Salesman Problem</title>
      <link>https://graphdeeplearning.github.io/publication/joshi-2019-learning/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/joshi-2019-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Graph Neural Networks for the Travelling Salesman Problem</title>
      <link>https://graphdeeplearning.github.io/talk/informs-oct2019/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/talk/informs-oct2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Graph Convolutional Neural Networks for Molecule Generation</title>
      <link>https://graphdeeplearning.github.io/talk/ipam-sept2019/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/talk/ipam-sept2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Combinatorial Optimization</title>
      <link>https://graphdeeplearning.github.io/project/combinatorial-optimization/</link>
      <pubDate>Tue, 17 Sep 2019 22:20:35 +0800</pubDate>
      <guid>https://graphdeeplearning.github.io/project/combinatorial-optimization/</guid>
      <description>&lt;h2 id=&#34;operations-research-and-combinatorial-problems&#34;&gt;Operations Research and Combinatorial Problems&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Operations_research&#34;&gt;Operations Research (OR)&lt;/a&gt;&lt;/strong&gt; started in the first world war as an initiative to use mathematics and computer science to assist military planners in their decisions. Nowadays it is widely used in the industry, including but not limited to transportation, supply chain, energy, finance, and scheduling.&lt;/p&gt;
&lt;p&gt;OR Problems are formulated as integer constrained optimization, &lt;em&gt;i.e.&lt;/em&gt;, with integral or binary variables (called decision variables).
While not all such problems are hard to solve (&lt;em&gt;e.g.&lt;/em&gt;, finding the shortest path between two locations), we concentrate on &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Combinatorial_optimization&#34;&gt;Combinatorial (NP-Hard) problems&lt;/a&gt;&lt;/strong&gt;. 
NP-Hard problems are &lt;em&gt;impossible&lt;/em&gt; to solve optimally at large scales as exhaustively searching for their solutions is beyond the limits of modern computers.
The &lt;a href=&#34;https://en.wikipedia.org/wiki/Travelling_salesman_problem&#34;&gt;Travelling Salesman Problem (TSP)&lt;/a&gt; and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Minimum_spanning_tree&#34;&gt;Minimum Spanning Tree Problem (MST)&lt;/a&gt; are two of the most popular examples for such problems defined using graphs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;tsp-gif.gif&#34; alt=&#34;TSP GIF&#34;&gt;
&lt;em&gt;TSP asks the following question: Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city? Formally, given a graph, one needs to search the space of permutations to find an optimal sequence of nodes, called a tour, with minimal total edge weights (tour length).&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;neural-combinatorial-optimization&#34;&gt;Neural Combinatorial Optimization&lt;/h2&gt;
&lt;p&gt;Although handcrafted heuristic algorithms are able to solve problems such as TSP with up to a million variables,
designing good heuristics often requires significant specialized knowledge and years of trial-and-error.
The state-of-the-art TSP solver, &lt;a href=&#34;http://www.math.uwaterloo.ca/tsp/concorde.html&#34;&gt;Concorde&lt;/a&gt;, leverages &lt;a href=&#34;https://www.youtube.com/watch?v=q8nQTNvCrjE&#34;&gt;over 50 years of research&lt;/a&gt; on linear programming, cutting plane algorithms and branch-and-bound.
At our lab, we&#39;re working on &lt;strong&gt;automating&lt;/strong&gt; and &lt;strong&gt;augmenting&lt;/strong&gt; such expert intuition through Machine Learning [&lt;a href=&#34;https://arxiv.org/abs/1811.06128&#34;&gt;Bengio &lt;em&gt;et al.&lt;/em&gt;, 2018&lt;/a&gt;].&lt;/p&gt;
&lt;p&gt;Since most problems are highly structured, heuristics take the form of rules or policies to make sequential decisions, &lt;em&gt;e.g.&lt;/em&gt;, determine the TSP tour one city at a time. 
Our research uses deep neural networks to parameterize these policies and train them directly from problem instances.
In particular, &lt;strong&gt;Graph Neural Networks&lt;/strong&gt; are the perfect fit for the task because they naturally operate on the graph structure of these problems.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;pipeline.png&#34; alt=&#34;End-to-end pipeline&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quantum Chemistry</title>
      <link>https://graphdeeplearning.github.io/project/chemistry/</link>
      <pubDate>Tue, 17 Sep 2019 22:20:35 +0800</pubDate>
      <guid>https://graphdeeplearning.github.io/project/chemistry/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Spatial Graph ConvNets</title>
      <link>https://graphdeeplearning.github.io/project/spatial-convnets/</link>
      <pubDate>Tue, 17 Sep 2019 22:20:35 +0800</pubDate>
      <guid>https://graphdeeplearning.github.io/project/spatial-convnets/</guid>
      <description>&lt;h2 id=&#34;non-euclidean-and-graph-structured-data&#34;&gt;Non-Euclidean and Graph-structured Data&lt;/h2&gt;
&lt;p&gt;Classic deep learning architectures such as &lt;a href=&#34;http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf&#34;&gt;Convolutional Neural Networks (CNNs)&lt;/a&gt; and &lt;a href=&#34;https://www.bioinf.jku.at/publications/older/2604.pdf&#34;&gt;Recurrent Neural Networks (RNNs)&lt;/a&gt; require the input data domain to be regular, such as 2D or 3D Euclidean grids for Computer Vision and 1D lines for Natural Language Processing.&lt;/p&gt;
&lt;p&gt;However, most real-world data beyond images and language has an underlying structure that is &lt;strong&gt;non-Euclidean&lt;/strong&gt;.
Such complex data commonly occurs in science and engineering, and can be modelled by heterogeneous graphs.
Examples include chemical graphs, computer graphics, social networks, genetics, neuroscience, and sensor networks.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;graph-data.png&#34; alt=&#34;Graph structured data&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;graph-neural-networks&#34;&gt;Graph Neural Networks&lt;/h2&gt;
&lt;p&gt;Graph-structured data can be large and complex (in the case of social networks, on the scale of billions), and is a natural target for machine learning applications. 
However, designing models for learning from non-Euclidean data is challenging as there are no familiar properties such as coordinate systems, vector space structure, or shift invariance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Graph/Geometric Deep Learning&lt;/strong&gt; is an umbrella term for emerging techniques attempting to generalize deep neural networks to non-Euclidean domains such as graphs and manifolds [&lt;a href=&#34;https://arxiv.org/abs/1611.08097&#34;&gt;Bronstein &lt;em&gt;et al.&lt;/em&gt;, 2017&lt;/a&gt;].
We are interested to designing neural networks for graphs of arbitrary topologies and structures in order to solve generic graph problems, such as vertex classification, graph classification, graph regression, and graph generation.
These Graph Neural Network (GNN) architectures are used as backbones for challenging domain-specific applications in chemistry, social networks or graphics.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;gnn-layer.png&#34; alt=&#34;GNN Layer&#34;&gt;
&lt;em&gt;GNNs iteratively build representations of graphs through recursive neighborhood aggregation (or message passing), where each graph node gathers features from its neighbors to represent local graph structure.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graph Convolutional Neural Networks for Molecule Generation and Travelling Salesman Problem</title>
      <link>https://graphdeeplearning.github.io/talk/ipam-may2019/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/talk/ipam-may2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Efficient Graph Convolutional Network Technique for the Travelling Salesman Problem</title>
      <link>https://graphdeeplearning.github.io/publication/joshi-2019-efficient/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/joshi-2019-efficient/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GraphTSNE: A Visualization Technique for Graph-Structured Data</title>
      <link>https://graphdeeplearning.github.io/publication/leow-2019-graphtsne/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/leow-2019-graphtsne/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Convolutional Neural Networks on Graphs</title>
      <link>https://graphdeeplearning.github.io/talk/ipam-feb2018/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/talk/ipam-feb2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Experimental Comparison of Text Classification Techniques</title>
      <link>https://graphdeeplearning.github.io/publication/lakhotia-2018-experimental/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/lakhotia-2018-experimental/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Experimental Study of Neural Networks for Variable Graphs</title>
      <link>https://graphdeeplearning.github.io/publication/bresson-2018-experimental/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/bresson-2018-experimental/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Residual Gated Graph ConvNets</title>
      <link>https://graphdeeplearning.github.io/publication/bresson-2017-residual/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://graphdeeplearning.github.io/publication/bresson-2017-residual/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
